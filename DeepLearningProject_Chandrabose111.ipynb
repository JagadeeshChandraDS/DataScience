{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkQg1p4oBYg0"
   },
   "source": [
    "# Deep Learning Project: Pet Classifier using CNN\n",
    "\n",
    "Prepration\n",
    "- Extract the ipynb file and the data in the same folder\n",
    "\n",
    "Data Set\n",
    "- A production grade program as 10,000 training images\n",
    "- This is a small program with 20 images of cats and 20 images of dogs. \n",
    "- The evaluation set has 10 images of cats and 10 images of dogs\n",
    "\n",
    "Runs\n",
    "- The student is expected to run the 100-300 training step\n",
    "- A production grade code would have about 20k-50k training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZA7wAV_hBYg3"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wXskiQtBYg6"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MdObpOgPBhtO",
    "outputId": "9d249a78-c403-4692-b22c-d3a399245993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JAUYf_QqBuCW",
    "outputId": "692cc40e-9f14-4662-afdd-2a69ec275bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mdata\u001b[0m/  'DeepLearningProject - Chandrabose111.ipynb'\n"
     ]
    }
   ],
   "source": [
    "ls '/content/gdrive/My Drive/DLProj/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSILN93_Biu3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSnEJxVwBYhF"
   },
   "source": [
    "### Set hyper parameters\n",
    "- Run the program with three num_steps : 100,200,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfzmVB5FBYhG"
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "img_size = 32\n",
    "img_shape = (img_size, img_size)\n",
    "labels = {'cats': 0, 'dogs': 1}\n",
    "fc_size=32 #size of the output of final FC layer\n",
    "num_steps=300 #Try 100, 200, 300. number of steps that training data should be looped. Usually 20K\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoXziIh8BYhL"
   },
   "source": [
    "## Reading the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "Ykj6K_sZBYhM",
    "outputId": "a715eba9-591a-4a48-fcff-b938c1542b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train image set 40\n",
      "X_data shape: (40, 32, 32, 3)\n",
      "y_data shape: (40,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAAC2CAYAAABNl8ZfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_images_classes(basepath,imgSize=img_size):\n",
    "    image_stack = []\n",
    "    label_stack = []\n",
    "\n",
    "    for counter, l in enumerate(labels):\n",
    "        path = os.path.join(basepath, l,'*g')\n",
    "        for img in glob.glob(path):\n",
    "            image = cv2.imread(img)\n",
    "            im_resize = cv2.resize(image,(img_shape), interpolation=cv2.INTER_CUBIC)\n",
    "            image_stack.append(im_resize)\n",
    "            label_stack.append(labels[l])            \n",
    "    return np.array(image_stack), np.array(label_stack)\n",
    "\n",
    "X_train, y_train = read_images_classes('/content/gdrive/My Drive/DLProj/data/train')\n",
    "X_test, y_test = read_images_classes('/content/gdrive/My Drive/DLProj/data/test')\n",
    "\n",
    "#test a sample image\n",
    "print('length of train image set',len(X_train))\n",
    "print('X_data shape:', X_train.shape)\n",
    "print('y_data shape:', y_train.shape)\n",
    "fig1 = plt.figure() \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "img = cv2.resize(X_train[0],(32,32), interpolation=cv2.INTER_CUBIC)\n",
    "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5339
    },
    "colab_type": "code",
    "id": "Tq8H-capHQA4",
    "outputId": "086cd43a-6f98-4226-dfa7-07fcea79400d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 86,  90,  91],\n",
       "         [ 40,  61,  83],\n",
       "         [ 42,  50,  59],\n",
       "         ...,\n",
       "         [110, 112, 106],\n",
       "         [102, 104,  98],\n",
       "         [ 93,  93,  87]],\n",
       "\n",
       "        [[ 87,  90,  94],\n",
       "         [152, 159, 184],\n",
       "         [184, 174, 196],\n",
       "         ...,\n",
       "         [119, 119, 113],\n",
       "         [112, 112, 106],\n",
       "         [103, 103,  97]],\n",
       "\n",
       "        [[142, 140, 139],\n",
       "         [142, 141, 146],\n",
       "         [142, 141, 154],\n",
       "         ...,\n",
       "         [128, 128, 122],\n",
       "         [122, 122, 116],\n",
       "         [111, 111, 105]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 96, 148, 178],\n",
       "         [100, 153, 180],\n",
       "         [108, 163, 194],\n",
       "         ...,\n",
       "         [ 66,  73,  74],\n",
       "         [ 58,  66,  65],\n",
       "         [ 47,  58,  62]],\n",
       "\n",
       "        [[ 85, 135, 165],\n",
       "         [ 94, 144, 171],\n",
       "         [ 99, 154, 185],\n",
       "         ...,\n",
       "         [128, 129, 125],\n",
       "         [117, 116, 106],\n",
       "         [ 56,  63,  65]],\n",
       "\n",
       "        [[ 79, 129, 156],\n",
       "         [ 80, 134, 169],\n",
       "         [ 85, 136, 169],\n",
       "         ...,\n",
       "         [130, 129, 125],\n",
       "         [111, 111, 106],\n",
       "         [ 42,  47,  48]]],\n",
       "\n",
       "\n",
       "       [[[169, 188, 196],\n",
       "         [155, 182, 192],\n",
       "         [189, 206, 219],\n",
       "         ...,\n",
       "         [160, 177, 190],\n",
       "         [159, 175, 187],\n",
       "         [160, 176, 189]],\n",
       "\n",
       "        [[188, 195, 202],\n",
       "         [139, 153, 165],\n",
       "         [143, 153, 161],\n",
       "         ...,\n",
       "         [168, 187, 200],\n",
       "         [172, 189, 202],\n",
       "         [160, 176, 192]],\n",
       "\n",
       "        [[152, 175, 187],\n",
       "         [224, 233, 237],\n",
       "         [183, 198, 206],\n",
       "         ...,\n",
       "         [173, 196, 208],\n",
       "         [171, 185, 197],\n",
       "         [169, 184, 195]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 80,  96, 108],\n",
       "         [106, 125, 136],\n",
       "         [149, 168, 178],\n",
       "         ...,\n",
       "         [137, 152, 161],\n",
       "         [169, 185, 192],\n",
       "         [166, 179, 187]],\n",
       "\n",
       "        [[165, 183, 194],\n",
       "         [153, 167, 179],\n",
       "         [134, 152, 159],\n",
       "         ...,\n",
       "         [169, 184, 193],\n",
       "         [175, 193, 200],\n",
       "         [123, 141, 148]],\n",
       "\n",
       "        [[171, 192, 203],\n",
       "         [147, 165, 172],\n",
       "         [135, 153, 160],\n",
       "         ...,\n",
       "         [180, 195, 204],\n",
       "         [198, 210, 214],\n",
       "         [168, 184, 191]]],\n",
       "\n",
       "\n",
       "       [[[145, 149, 160],\n",
       "         [164, 168, 179],\n",
       "         [166, 173, 186],\n",
       "         ...,\n",
       "         [139, 154, 162],\n",
       "         [ 92,  91, 132],\n",
       "         [137, 142, 152]],\n",
       "\n",
       "        [[147, 152, 161],\n",
       "         [171, 174, 188],\n",
       "         [172, 178, 191],\n",
       "         ...,\n",
       "         [133, 138, 153],\n",
       "         [168, 177, 187],\n",
       "         [164, 166, 174]],\n",
       "\n",
       "        [[150, 155, 164],\n",
       "         [172, 175, 189],\n",
       "         [174, 180, 193],\n",
       "         ...,\n",
       "         [181, 181, 211],\n",
       "         [185, 194, 208],\n",
       "         [172, 179, 192]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[161, 174, 189],\n",
       "         [ 46,  59,  67],\n",
       "         [122, 126, 135],\n",
       "         ...,\n",
       "         [ 24,  23,  23],\n",
       "         [ 85,  65,  62],\n",
       "         [ 81,  59,  60]],\n",
       "\n",
       "        [[ 35,  36,  40],\n",
       "         [ 21,  34,  42],\n",
       "         [ 88,  99, 107],\n",
       "         ...,\n",
       "         [ 36,  31,  33],\n",
       "         [ 34,  28,  27],\n",
       "         [ 69,  51,  50]],\n",
       "\n",
       "        [[ 12,  21,  20],\n",
       "         [ 14,  16,  20],\n",
       "         [ 15,  30,  34],\n",
       "         ...,\n",
       "         [ 15,  11,  12],\n",
       "         [ 12,  14,   6],\n",
       "         [ 19,  15,   9]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[109, 111, 109],\n",
       "         [ 81,  81,  81],\n",
       "         [122, 122, 122],\n",
       "         ...,\n",
       "         [140, 138, 137],\n",
       "         [144, 142, 141],\n",
       "         [158, 154, 153]],\n",
       "\n",
       "        [[ 78,  80,  80],\n",
       "         [109, 111, 111],\n",
       "         [131, 130, 132],\n",
       "         ...,\n",
       "         [148, 146, 146],\n",
       "         [155, 153, 152],\n",
       "         [152, 150, 149]],\n",
       "\n",
       "        [[ 84,  86,  86],\n",
       "         [ 91,  93,  93],\n",
       "         [ 83,  88,  89],\n",
       "         ...,\n",
       "         [139, 137, 137],\n",
       "         [147, 145, 144],\n",
       "         [132, 130, 129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[130, 128, 127],\n",
       "         [130, 128, 127],\n",
       "         [112, 112, 112],\n",
       "         ...,\n",
       "         [132, 132, 132],\n",
       "         [131, 127, 126],\n",
       "         [149, 146, 142]],\n",
       "\n",
       "        [[151, 149, 148],\n",
       "         [133, 131, 130],\n",
       "         [107, 107, 107],\n",
       "         ...,\n",
       "         [132, 128, 127],\n",
       "         [155, 151, 150],\n",
       "         [127, 122, 119]],\n",
       "\n",
       "        [[125, 123, 122],\n",
       "         [149, 147, 146],\n",
       "         [112, 112, 112],\n",
       "         ...,\n",
       "         [134, 130, 129],\n",
       "         [149, 145, 144],\n",
       "         [136, 131, 128]]],\n",
       "\n",
       "\n",
       "       [[[ 48,  96, 129],\n",
       "         [ 87, 114, 123],\n",
       "         [ 96, 116, 121],\n",
       "         ...,\n",
       "         [ 99, 122, 137],\n",
       "         [100, 124, 136],\n",
       "         [100, 123, 139]],\n",
       "\n",
       "        [[111, 137, 151],\n",
       "         [100, 114, 117],\n",
       "         [100, 119, 126],\n",
       "         ...,\n",
       "         [ 97, 123, 134],\n",
       "         [ 96, 122, 128],\n",
       "         [101, 125, 137]],\n",
       "\n",
       "        [[155, 163, 164],\n",
       "         [168, 167, 160],\n",
       "         [159, 162, 162],\n",
       "         ...,\n",
       "         [ 95, 120, 130],\n",
       "         [ 99, 124, 132],\n",
       "         [ 99, 121, 133]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[226, 218, 201],\n",
       "         [222, 214, 197],\n",
       "         [210, 202, 185],\n",
       "         ...,\n",
       "         [ 88, 103, 101],\n",
       "         [ 83,  97, 103],\n",
       "         [ 87,  98, 102]],\n",
       "\n",
       "        [[218, 212, 192],\n",
       "         [220, 213, 194],\n",
       "         [214, 204, 186],\n",
       "         ...,\n",
       "         [ 86, 100, 106],\n",
       "         [ 83,  99,  98],\n",
       "         [ 83,  99,  98]],\n",
       "\n",
       "        [[222, 211, 191],\n",
       "         [216, 206, 186],\n",
       "         [218, 206, 188],\n",
       "         ...,\n",
       "         [ 79,  94,  95],\n",
       "         [ 81,  94, 102],\n",
       "         [ 79,  94,  97]]],\n",
       "\n",
       "\n",
       "       [[[ 38,  79, 127],\n",
       "         [  5,  47,  92],\n",
       "         [ 73, 113, 166],\n",
       "         ...,\n",
       "         [  0,   2,   2],\n",
       "         [ 39,  74, 118],\n",
       "         [ 62,  89, 124]],\n",
       "\n",
       "        [[ 34, 102, 124],\n",
       "         [ 43,  91, 128],\n",
       "         [ 59,  96, 146],\n",
       "         ...,\n",
       "         [  2,   2,   2],\n",
       "         [ 59,  79,  85],\n",
       "         [ 59,  89,  94]],\n",
       "\n",
       "        [[115, 154, 203],\n",
       "         [ 54,  92, 124],\n",
       "         [ 62, 104, 147],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  2,   5,   5],\n",
       "         [  4,  19,  27]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[213, 232, 233],\n",
       "         [230, 246, 243],\n",
       "         [215, 239, 237],\n",
       "         ...,\n",
       "         [222, 243, 244],\n",
       "         [210, 230, 231],\n",
       "         [194, 220, 220]],\n",
       "\n",
       "        [[230, 249, 248],\n",
       "         [232, 250, 249],\n",
       "         [234, 252, 251],\n",
       "         ...,\n",
       "         [228, 246, 247],\n",
       "         [216, 235, 238],\n",
       "         [195, 220, 219]],\n",
       "\n",
       "        [[221, 241, 242],\n",
       "         [221, 241, 242],\n",
       "         [230, 252, 250],\n",
       "         ...,\n",
       "         [228, 246, 245],\n",
       "         [223, 243, 244],\n",
       "         [216, 238, 236]]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1,32,32,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6CdAmugbBYhS"
   },
   "source": [
    "### Assignment: Define the tensorflow model\n",
    "\n",
    "The model should have the following layers\n",
    "- input later\n",
    "- conv layer 1 with 32 filters of kernel  size[5,5],\n",
    "- pooling layer 1 with pool size[2,2] and stride 2\n",
    "- conv layer 2 with 64 filters of kernel  size[5,5],\n",
    "- pooling layer 2 with pool size[2,2] and stride 2\n",
    "- dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
    "- drop out layer with droput probability 0.4\n",
    "- predict the class by doing a softmax on the output of the dropout layers\n",
    "\n",
    "Training\n",
    "- For training fefine the loss function and minimize it\n",
    "- For evaluation calculate the accuracy\n",
    "\n",
    "Reading Material\n",
    "- For ideas look at tensorflow layers tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIoYE8BuBYhU"
   },
   "source": [
    "##Defining the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIegtWSpBYhV"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "x = tf.placeholder(dtype=tf.float64, shape=[None, 32, 32, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "c1 = tf.layers.conv2d(inputs=x, activation=tf.nn.relu, filters=64, kernel_size=[5,5], padding='VALID', strides=1) #input to c1 is x\n",
    "p1 = tf.layers.max_pooling2d(inputs=c1, pool_size=[2,2], strides=2) #input to p1 is c1\n",
    "\n",
    "c2 = tf.layers.conv2d(inputs=p1, activation=tf.nn.relu, filters=32, kernel_size=[5,5], padding='VALID', strides=1) #input to c2 is p1\n",
    "p2 = tf.layers.max_pooling2d(inputs=c2, pool_size=[2,2], strides=2) #input to p2 is c2\n",
    "    \n",
    "f = tf.contrib.layers.flatten(p2) \n",
    " \n",
    "fc1 = tf.layers.dense(inputs=f, units=32, activation=tf.nn.relu)\n",
    "drop_out = tf.nn.dropout(fc1, rate=0.4)\n",
    "logits = tf.layers.dense(inputs = drop_out, units=2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOtk2E-nYfi2"
   },
   "source": [
    "###Calculating Loss and Accuracy of The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zboaFKmJILje"
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(dtype=tf.int64)\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits) # No need of onehot encodings\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "trainer = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUelAJHaIkUk"
   },
   "source": [
    "###Training for 100 epochs/iterations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "oRPqXc4EIxm6",
    "outputId": "285dcb1f-a2ce-450b-c233-e0880ed20367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Loss: 0.73 | Accuracy: 0.35\n",
      "Step 5 - Loss: 0.68 | Accuracy: 0.62\n",
      "Step 10 - Loss: 0.65 | Accuracy: 0.70\n",
      "Step 15 - Loss: 0.59 | Accuracy: 0.65\n",
      "Step 20 - Loss: 0.55 | Accuracy: 0.73\n",
      "Step 25 - Loss: 0.50 | Accuracy: 0.75\n",
      "Step 30 - Loss: 0.38 | Accuracy: 0.88\n",
      "Step 35 - Loss: 0.34 | Accuracy: 0.88\n",
      "Step 40 - Loss: 0.27 | Accuracy: 0.93\n",
      "Step 45 - Loss: 0.21 | Accuracy: 0.98\n",
      "Step 50 - Loss: 0.18 | Accuracy: 0.98\n",
      "Step 55 - Loss: 0.17 | Accuracy: 0.95\n",
      "Step 60 - Loss: 0.10 | Accuracy: 0.98\n",
      "Step 65 - Loss: 0.07 | Accuracy: 0.98\n",
      "Step 70 - Loss: 0.05 | Accuracy: 1.00\n",
      "Step 75 - Loss: 0.03 | Accuracy: 1.00\n",
      "Step 80 - Loss: 0.08 | Accuracy: 0.98\n",
      "Step 85 - Loss: 0.02 | Accuracy: 1.00\n",
      "Step 90 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 95 - Loss: 0.03 | Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epochs):\n",
    "    sess.run([trainer], feed_dict={x:X_train/255., y:y_train, keep_prob:0.6})\n",
    "    [acc, l] = sess.run([accuracy, loss], feed_dict={x:X_train/255., y:y_train, keep_prob:1})\n",
    "    \n",
    "    if i%5==0:\n",
    "        print('Step %d - Loss: %.2f | Accuracy: %.2f'%(i,np.mean(l),acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GbY5a4xsT5Cf",
    "outputId": "c7e425ef-e168-4e00-fe51-b4dc1430fe0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Evaluation & Final accuracy and loss for 100 iterations\n",
    "\n",
    "[yh] = sess.run([logits], feed_dict={x:X_train, y:y_train, keep_prob:1})\n",
    "pred_class_train = np.argmax(yh, axis=1)\n",
    "\n",
    "[yh_val] = sess.run([logits], feed_dict={x:X_test, keep_prob:1})\n",
    "pred_class_val = np.argmax(yh_val, axis=1)\n",
    "\n",
    "cm_val = confusion_matrix(y_true=y_test, y_pred=pred_class_val)\n",
    "acc_val = np.trace(cm_val)/np.sum(cm_val)\n",
    "print(acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMSOubaQJF3-"
   },
   "source": [
    "###Training for 200 epochs/iterations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "colab_type": "code",
    "id": "y25aO3tHJqap",
    "outputId": "892b1129-1c4a-4f68-e28b-28da034f37ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Loss: 0.73 | Accuracy: 0.35\n",
      "Step 5 - Loss: 0.68 | Accuracy: 0.62\n",
      "Step 10 - Loss: 0.65 | Accuracy: 0.70\n",
      "Step 15 - Loss: 0.59 | Accuracy: 0.65\n",
      "Step 20 - Loss: 0.55 | Accuracy: 0.73\n",
      "Step 25 - Loss: 0.50 | Accuracy: 0.75\n",
      "Step 30 - Loss: 0.38 | Accuracy: 0.88\n",
      "Step 35 - Loss: 0.34 | Accuracy: 0.88\n",
      "Step 40 - Loss: 0.27 | Accuracy: 0.93\n",
      "Step 45 - Loss: 0.21 | Accuracy: 0.98\n",
      "Step 50 - Loss: 0.18 | Accuracy: 0.98\n",
      "Step 55 - Loss: 0.17 | Accuracy: 0.95\n",
      "Step 60 - Loss: 0.10 | Accuracy: 0.98\n",
      "Step 65 - Loss: 0.07 | Accuracy: 0.98\n",
      "Step 70 - Loss: 0.05 | Accuracy: 1.00\n",
      "Step 75 - Loss: 0.03 | Accuracy: 1.00\n",
      "Step 80 - Loss: 0.08 | Accuracy: 0.98\n",
      "Step 85 - Loss: 0.02 | Accuracy: 1.00\n",
      "Step 90 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 95 - Loss: 0.03 | Accuracy: 1.00\n",
      "Step 100 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 105 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 110 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 115 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 120 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 125 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 130 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 135 - Loss: 0.02 | Accuracy: 1.00\n",
      "Step 140 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 145 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 150 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 155 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 160 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 165 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 170 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 175 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 180 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 185 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 190 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 195 - Loss: 0.00 | Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epochs):\n",
    "    sess.run([trainer], feed_dict={x:X_train/255., y:y_train, keep_prob:0.6})\n",
    "    [acc, l] = sess.run([accuracy, loss], feed_dict={x:X_train/255., y:y_train, keep_prob:1})\n",
    "    \n",
    "    if i%5==0:\n",
    "        print('Step %d - Loss: %.2f | Accuracy: %.2f'%(i,np.mean(l),acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SPbkD75CXBX1",
    "outputId": "437e5bf9-c145-473f-9cf9-1b4b770cdd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Evaluation & Final accuracy and loss for 200 iterations\n",
    "    \n",
    "[yh] = sess.run([logits], feed_dict={x:X_train, y:y_train, keep_prob:1})\n",
    "pred_class_train = np.argmax(yh, axis=1)\n",
    "\n",
    "[yh_val] = sess.run([logits], feed_dict={x:X_test, keep_prob:1})\n",
    "pred_class_val = np.argmax(yh_val, axis=1)\n",
    "\n",
    "cm_val = confusion_matrix(y_true=y_test, y_pred=pred_class_val)\n",
    "acc_val = np.trace(cm_val)/np.sum(cm_val)\n",
    "print(acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "flve0gojKQz7"
   },
   "source": [
    "###Training for 300 epochs/iterations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1057
    },
    "colab_type": "code",
    "id": "a-TUbIDfKNr9",
    "outputId": "f3101ccf-d269-40f6-8586-426da4137fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Loss: 0.73 | Accuracy: 0.35\n",
      "Step 5 - Loss: 0.68 | Accuracy: 0.62\n",
      "Step 10 - Loss: 0.65 | Accuracy: 0.70\n",
      "Step 15 - Loss: 0.59 | Accuracy: 0.65\n",
      "Step 20 - Loss: 0.55 | Accuracy: 0.73\n",
      "Step 25 - Loss: 0.50 | Accuracy: 0.75\n",
      "Step 30 - Loss: 0.38 | Accuracy: 0.88\n",
      "Step 35 - Loss: 0.34 | Accuracy: 0.88\n",
      "Step 40 - Loss: 0.27 | Accuracy: 0.93\n",
      "Step 45 - Loss: 0.21 | Accuracy: 0.98\n",
      "Step 50 - Loss: 0.18 | Accuracy: 0.98\n",
      "Step 55 - Loss: 0.17 | Accuracy: 0.95\n",
      "Step 60 - Loss: 0.10 | Accuracy: 0.98\n",
      "Step 65 - Loss: 0.07 | Accuracy: 0.98\n",
      "Step 70 - Loss: 0.05 | Accuracy: 1.00\n",
      "Step 75 - Loss: 0.03 | Accuracy: 1.00\n",
      "Step 80 - Loss: 0.08 | Accuracy: 0.98\n",
      "Step 85 - Loss: 0.02 | Accuracy: 1.00\n",
      "Step 90 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 95 - Loss: 0.03 | Accuracy: 1.00\n",
      "Step 100 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 105 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 110 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 115 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 120 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 125 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 130 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 135 - Loss: 0.02 | Accuracy: 1.00\n",
      "Step 140 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 145 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 150 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 155 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 160 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 165 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 170 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 175 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 180 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 185 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 190 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 195 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 200 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 205 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 210 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 215 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 220 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 225 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 230 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 235 - Loss: 0.01 | Accuracy: 1.00\n",
      "Step 240 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 245 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 250 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 255 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 260 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 265 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 270 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 275 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 280 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 285 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 290 - Loss: 0.00 | Accuracy: 1.00\n",
      "Step 295 - Loss: 0.00 | Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epochs):\n",
    "    sess.run([trainer], feed_dict={x:X_train/255., y:y_train, keep_prob:0.6})\n",
    "    [acc, l] = sess.run([accuracy, loss], feed_dict={x:X_train/255., y:y_train, keep_prob:1})\n",
    "    \n",
    "    if i%5==0:\n",
    "        print('Step %d - Loss: %.2f | Accuracy: %.2f'%(i,np.mean(l),acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dACDpP49NtkS",
    "outputId": "30b803a0-ffe6-431e-8ae3-d5010d265125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Evaluation & Final accuracy and loss for 300 iterations \n",
    "\n",
    "[yh] = sess.run([logits], feed_dict={x:X_train, y:y_train, keep_prob:1})\n",
    "pred_class_train = np.argmax(yh, axis=1)\n",
    "\n",
    "[yh_val] = sess.run([logits], feed_dict={x:X_test, keep_prob:1})\n",
    "pred_class_val = np.argmax(yh_val, axis=1)\n",
    "\n",
    "cm_val = confusion_matrix(y_true=y_test, y_pred=pred_class_val)\n",
    "acc_val = np.trace(cm_val)/np.sum(cm_val)\n",
    "print(acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3JmxWnkY1o0"
   },
   "source": [
    "#### =============================================================="
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DeepLearningProject - Chandrabose111.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
